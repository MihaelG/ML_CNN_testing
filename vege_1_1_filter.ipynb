{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of CNN with 1x1 filter\n",
    "\n",
    "Zašto korištenje 1x1 filtera?\n",
    "Zato da algoritam pronađe vezu između true ishoda i dubine ulaza.\n",
    "\n",
    "Planiram koristiti:\n",
    "- INICIJALIZACIJA??\n",
    "- aktivacijska funkcija: Relu\n",
    "- normalizacija: Batch Normalization - zapravo, s obzirom da je Batch norm. koristan prvenstveno kod dubokih mreža, pokušati ću prvo bez toga, da vidim kako funkcionira.\n",
    "- regularizacija: Dropout\n",
    "- OPTIMIZER? ADAM?\n",
    "\n",
    "S obzirom da ima malo podataka, razmisli može li se nekako povećati broj podataka data augmentation tehnikama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION\n",
      "length of the fixed array is  199400\n",
      "test :  ['V', '339', '201', '238', '278', '186', '298', '298', '253']\n"
     ]
    }
   ],
   "source": [
    "print ('DATA PREPARATION')\n",
    "vege_csv = csv.reader(open('vegetacija.csv', newline=''), delimiter=' ', quotechar='|')\n",
    "\n",
    "vege_array = []\n",
    "\n",
    "\n",
    "for row in vege_csv:\n",
    "\tred_array = []\n",
    "\titems = row[0].split(';')\n",
    "\tfor i in items:\n",
    "\t\tred_array.append(i)\n",
    "\n",
    "\tvege_array.append(red_array)\n",
    "\n",
    "\n",
    "klase = []\n",
    "values = []\n",
    "\n",
    "vege_array_fix = vege_array[:-4]\n",
    "\n",
    "print ('length of the fixed array is ', len (vege_array_fix))\n",
    "\n",
    "for r in vege_array_fix:\n",
    "    value_row = []\n",
    "    i = 0\n",
    "    while i < len(r):\n",
    "        if i == 0:\n",
    "            if r[i] == 'X':\n",
    "                klase.append(0)\n",
    "            if r[i] == 'V':\n",
    "                klase.append(1)\n",
    "            if r[i] == 'N':\n",
    "                klase.append(2)\n",
    "        else:\n",
    "            value_row.append(int(r[i]))\n",
    "        i = i + 1\n",
    "    values.append(value_row)\n",
    "\n",
    "print ('test : ', vege_array[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(values, klase, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 1\n",
    "width = 1\n",
    "channels = 8\n",
    "# n_inputs = height * width\n",
    "\n",
    "conv1_fmaps = 16\n",
    "conv1_ksize = 1\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 32\n",
    "conv2_ksize = 1\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "n_fc1 = 64\n",
    "n_outputs = 3\n",
    "\n",
    "# n_inputs = len(X_train)\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, channels], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")    \n",
    "\n",
    "\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 1, 1, 1], strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 1 * 1])\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159520\n"
     ]
    }
   ],
   "source": [
    "print (len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = X_train[:63808]\n",
    "X_train = X_train[63808:]\n",
    "\n",
    "y_valid = y_train[:63808]\n",
    "y_train = y_train[63808:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95712\n"
     ]
    }
   ],
   "source": [
    "train_array_length = len(X_train)\n",
    "print (train_array_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moja egzekucijska funkcija\n",
    "\n",
    "# n_epochs = 100\n",
    "# batch_size = 20\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     init.run()\n",
    "#     for epoch in range(n_epochs):\n",
    "#         for iteration in range(int(len(X_train)/batch_size)):\n",
    "#             X_batch, y_batch = X_train.train.next_batch(batch_size)\n",
    "#             sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "#         loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid, y: y_valid})\n",
    "#         if loss_val < best_loss:\n",
    "#             save_path = saver.save(sess, \"./vege_model.ckpt\")\n",
    "#             best_loss = loss_val\n",
    "#             checks_without_progress = 0\n",
    "#         else:\n",
    "#             checks_without_progress += 1\n",
    "#             if checks_without_progress > max_checks_without_progress:\n",
    "#                 print(\"Early stopping!\")\n",
    "#                 break\n",
    "#         print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "#             epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     saver.restore(sess, \"./vege_model.ckpt\")\n",
    "#     acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "#     print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# n_epochs = 10\n",
    "# batch_size = 20\n",
    "\n",
    "# max_checks_without_progress = 20\n",
    "# checks_without_progress = 0\n",
    "# best_loss = np.infty\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     init.run()\n",
    "\n",
    "#     for epoch in range(n_epochs):\n",
    "#         rnd_idx = np.random.permutation(train_array_length)\n",
    "#         for rnd_indices in np.array_split(rnd_idx, train_array_length // batch_size):\n",
    "#             print (rnd_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.613481\tBest loss: 0.613481\tAccuracy: 81.70%\n",
      "1\tValidation loss: 0.578504\tBest loss: 0.578504\tAccuracy: 80.76%\n",
      "2\tValidation loss: 0.568325\tBest loss: 0.568325\tAccuracy: 81.74%\n",
      "3\tValidation loss: 0.562645\tBest loss: 0.562645\tAccuracy: 81.80%\n",
      "4\tValidation loss: 0.561915\tBest loss: 0.561915\tAccuracy: 81.86%\n",
      "5\tValidation loss: 0.572783\tBest loss: 0.561915\tAccuracy: 81.73%\n",
      "6\tValidation loss: 0.561641\tBest loss: 0.561641\tAccuracy: 81.80%\n",
      "7\tValidation loss: 0.557554\tBest loss: 0.557554\tAccuracy: 81.71%\n",
      "8\tValidation loss: 0.552568\tBest loss: 0.552568\tAccuracy: 81.84%\n",
      "9\tValidation loss: 0.545297\tBest loss: 0.545297\tAccuracy: 81.82%\n",
      "10\tValidation loss: 0.544298\tBest loss: 0.544298\tAccuracy: 81.74%\n",
      "11\tValidation loss: 0.547756\tBest loss: 0.544298\tAccuracy: 81.73%\n",
      "12\tValidation loss: 0.547996\tBest loss: 0.544298\tAccuracy: 81.85%\n",
      "13\tValidation loss: 0.550838\tBest loss: 0.544298\tAccuracy: 81.79%\n",
      "14\tValidation loss: 0.542863\tBest loss: 0.542863\tAccuracy: 81.82%\n",
      "15\tValidation loss: 0.544657\tBest loss: 0.542863\tAccuracy: 81.85%\n",
      "16\tValidation loss: 0.536758\tBest loss: 0.536758\tAccuracy: 81.83%\n",
      "17\tValidation loss: 0.539259\tBest loss: 0.536758\tAccuracy: 81.87%\n",
      "18\tValidation loss: 0.537484\tBest loss: 0.536758\tAccuracy: 81.86%\n",
      "19\tValidation loss: 0.550094\tBest loss: 0.536758\tAccuracy: 81.79%\n",
      "20\tValidation loss: 0.539540\tBest loss: 0.536758\tAccuracy: 81.81%\n",
      "21\tValidation loss: 0.543927\tBest loss: 0.536758\tAccuracy: 81.80%\n",
      "22\tValidation loss: 0.531332\tBest loss: 0.531332\tAccuracy: 81.86%\n",
      "23\tValidation loss: 0.534869\tBest loss: 0.531332\tAccuracy: 81.83%\n",
      "24\tValidation loss: 0.566689\tBest loss: 0.531332\tAccuracy: 81.75%\n",
      "25\tValidation loss: 0.533738\tBest loss: 0.531332\tAccuracy: 81.78%\n",
      "26\tValidation loss: 0.535843\tBest loss: 0.531332\tAccuracy: 81.64%\n",
      "27\tValidation loss: 0.539196\tBest loss: 0.531332\tAccuracy: 81.74%\n",
      "28\tValidation loss: 0.533787\tBest loss: 0.531332\tAccuracy: 81.70%\n",
      "29\tValidation loss: 0.531288\tBest loss: 0.531288\tAccuracy: 81.78%\n",
      "30\tValidation loss: 0.542162\tBest loss: 0.531288\tAccuracy: 81.71%\n",
      "31\tValidation loss: 0.532221\tBest loss: 0.531288\tAccuracy: 81.80%\n",
      "32\tValidation loss: 0.528207\tBest loss: 0.528207\tAccuracy: 81.85%\n",
      "33\tValidation loss: 0.532805\tBest loss: 0.528207\tAccuracy: 81.87%\n",
      "34\tValidation loss: 0.540348\tBest loss: 0.528207\tAccuracy: 81.85%\n",
      "35\tValidation loss: 0.551371\tBest loss: 0.528207\tAccuracy: 81.69%\n",
      "36\tValidation loss: 0.547157\tBest loss: 0.528207\tAccuracy: 81.71%\n",
      "37\tValidation loss: 0.532851\tBest loss: 0.528207\tAccuracy: 81.55%\n",
      "38\tValidation loss: 0.536614\tBest loss: 0.528207\tAccuracy: 81.78%\n",
      "39\tValidation loss: 0.533775\tBest loss: 0.528207\tAccuracy: 81.84%\n",
      "40\tValidation loss: 0.535518\tBest loss: 0.528207\tAccuracy: 81.84%\n",
      "41\tValidation loss: 0.526011\tBest loss: 0.526011\tAccuracy: 81.83%\n",
      "42\tValidation loss: 0.539716\tBest loss: 0.526011\tAccuracy: 81.81%\n",
      "43\tValidation loss: 0.526616\tBest loss: 0.526011\tAccuracy: 81.86%\n",
      "44\tValidation loss: 0.529298\tBest loss: 0.526011\tAccuracy: 81.89%\n",
      "45\tValidation loss: 0.528582\tBest loss: 0.526011\tAccuracy: 81.91%\n",
      "46\tValidation loss: 0.524947\tBest loss: 0.524947\tAccuracy: 81.94%\n",
      "47\tValidation loss: 0.533141\tBest loss: 0.524947\tAccuracy: 81.77%\n",
      "48\tValidation loss: 0.526742\tBest loss: 0.524947\tAccuracy: 81.89%\n",
      "49\tValidation loss: 0.529561\tBest loss: 0.524947\tAccuracy: 81.88%\n",
      "50\tValidation loss: 0.571183\tBest loss: 0.524947\tAccuracy: 81.80%\n",
      "51\tValidation loss: 0.549556\tBest loss: 0.524947\tAccuracy: 81.79%\n",
      "52\tValidation loss: 0.527489\tBest loss: 0.524947\tAccuracy: 81.83%\n",
      "53\tValidation loss: 0.526782\tBest loss: 0.524947\tAccuracy: 81.83%\n",
      "54\tValidation loss: 0.524237\tBest loss: 0.524237\tAccuracy: 81.99%\n",
      "55\tValidation loss: 0.539429\tBest loss: 0.524237\tAccuracy: 81.77%\n",
      "56\tValidation loss: 0.528605\tBest loss: 0.524237\tAccuracy: 81.89%\n",
      "57\tValidation loss: 0.526110\tBest loss: 0.524237\tAccuracy: 81.89%\n",
      "58\tValidation loss: 0.540781\tBest loss: 0.524237\tAccuracy: 81.87%\n",
      "59\tValidation loss: 0.523200\tBest loss: 0.523200\tAccuracy: 81.86%\n",
      "60\tValidation loss: 0.528774\tBest loss: 0.523200\tAccuracy: 81.83%\n",
      "61\tValidation loss: 0.537193\tBest loss: 0.523200\tAccuracy: 81.70%\n",
      "62\tValidation loss: 0.530094\tBest loss: 0.523200\tAccuracy: 81.90%\n",
      "63\tValidation loss: 0.529169\tBest loss: 0.523200\tAccuracy: 81.97%\n",
      "64\tValidation loss: 0.525499\tBest loss: 0.523200\tAccuracy: 81.82%\n",
      "65\tValidation loss: 0.524143\tBest loss: 0.523200\tAccuracy: 81.91%\n",
      "66\tValidation loss: 0.525783\tBest loss: 0.523200\tAccuracy: 81.93%\n",
      "67\tValidation loss: 0.530975\tBest loss: 0.523200\tAccuracy: 81.82%\n",
      "68\tValidation loss: 0.525686\tBest loss: 0.523200\tAccuracy: 81.81%\n",
      "69\tValidation loss: 0.521974\tBest loss: 0.521974\tAccuracy: 81.86%\n",
      "70\tValidation loss: 0.529140\tBest loss: 0.521974\tAccuracy: 81.83%\n",
      "71\tValidation loss: 0.538770\tBest loss: 0.521974\tAccuracy: 81.68%\n",
      "72\tValidation loss: 0.518000\tBest loss: 0.518000\tAccuracy: 81.94%\n",
      "73\tValidation loss: 0.526167\tBest loss: 0.518000\tAccuracy: 81.87%\n",
      "74\tValidation loss: 0.519684\tBest loss: 0.518000\tAccuracy: 81.97%\n",
      "75\tValidation loss: 0.543914\tBest loss: 0.518000\tAccuracy: 81.48%\n",
      "76\tValidation loss: 0.526577\tBest loss: 0.518000\tAccuracy: 81.82%\n",
      "77\tValidation loss: 0.524394\tBest loss: 0.518000\tAccuracy: 81.75%\n",
      "78\tValidation loss: 0.528165\tBest loss: 0.518000\tAccuracy: 81.93%\n",
      "79\tValidation loss: 0.529675\tBest loss: 0.518000\tAccuracy: 81.91%\n",
      "80\tValidation loss: 0.535111\tBest loss: 0.518000\tAccuracy: 81.92%\n",
      "81\tValidation loss: 0.520519\tBest loss: 0.518000\tAccuracy: 81.79%\n",
      "82\tValidation loss: 0.528286\tBest loss: 0.518000\tAccuracy: 81.94%\n",
      "83\tValidation loss: 0.529193\tBest loss: 0.518000\tAccuracy: 81.93%\n",
      "84\tValidation loss: 0.527653\tBest loss: 0.518000\tAccuracy: 81.83%\n",
      "85\tValidation loss: 0.521960\tBest loss: 0.518000\tAccuracy: 81.94%\n",
      "86\tValidation loss: 0.521993\tBest loss: 0.518000\tAccuracy: 81.86%\n",
      "87\tValidation loss: 0.532779\tBest loss: 0.518000\tAccuracy: 81.79%\n",
      "88\tValidation loss: 0.526322\tBest loss: 0.518000\tAccuracy: 81.88%\n",
      "89\tValidation loss: 0.528498\tBest loss: 0.518000\tAccuracy: 81.46%\n",
      "90\tValidation loss: 0.538146\tBest loss: 0.518000\tAccuracy: 81.90%\n",
      "91\tValidation loss: 0.543483\tBest loss: 0.518000\tAccuracy: 81.58%\n",
      "92\tValidation loss: 0.514650\tBest loss: 0.514650\tAccuracy: 82.02%\n",
      "93\tValidation loss: 0.525197\tBest loss: 0.514650\tAccuracy: 81.98%\n",
      "94\tValidation loss: 0.518503\tBest loss: 0.514650\tAccuracy: 81.80%\n",
      "95\tValidation loss: 0.518160\tBest loss: 0.514650\tAccuracy: 81.99%\n",
      "96\tValidation loss: 0.530247\tBest loss: 0.514650\tAccuracy: 81.74%\n",
      "97\tValidation loss: 0.527624\tBest loss: 0.514650\tAccuracy: 81.72%\n",
      "98\tValidation loss: 0.548251\tBest loss: 0.514650\tAccuracy: 81.26%\n",
      "99\tValidation loss: 0.530745\tBest loss: 0.514650\tAccuracy: 81.72%\n",
      "INFO:tensorflow:Restoring parameters from ./vege_model.ckpt\n",
      "Final test accuracy: 82.13%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs = 100\n",
    "batch_size = 40\n",
    "\n",
    "max_checks_without_progress = 40\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
    "            X_batch = []\n",
    "            y_batch = []\n",
    "            for i in rnd_indices:\n",
    "                X_batch.append(X_train[i]) \n",
    "                y_batch.append(y_train[i])\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid, y: y_valid})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./vege_model.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./vege_model.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
